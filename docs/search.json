[
  {
    "objectID": "projectsql.html",
    "href": "projectsql.html",
    "title": "Policing Patterns Across Cities",
    "section": "",
    "text": "show code\nlibrary(RMariaDB)\nlibrary(DBI)\n\ncon_traffic &lt;- DBI::dbConnect(\n\n  RMariaDB::MariaDB(),\n\n  dbname = \"traffic\",\n\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n\n)\n\n\nCitations\nPierson, E., Simoiu, C., Overgoor, J., Corbett-Davies, S., Jenson, D., Shoemaker, A., Ramachandran, V., Barghouty, P., Phillips, C., Shroff, R., & Goel, S. (2020). A large-scale analysis of racial disparities in police stops across the United States. Nature Human Behaviour, 4(7), 736–745. https://doi.org/10.1038/s41562-020-0858-1\nStanford Open Policing Project. (2020). Traffic stop data (Standardized datasets) [Data set]. Stanford Computational Policy Lab. https://openpolicing.stanford.edu/data/\nIntroduction: In this project, I aim to explore the differences in traffic stop patterns involving Hispanic, Black, and white drivers across three major cities: San Diego, Chicago, and San Antonio to understand policing patterns. Using a compilation of the Stanford Open Policing Project data, I will examine three main components for my analysis. First, I will look at stop composition, the number of stops involving Hispanic, Black, and White drivers. The second is the search rates: how often Hispanic, Black, and White drivers are subjected to searches after being stopped. The third is the outcome of the stop (citation, warnings, arrests, other). Finally, I will create visualizations to summarize my findings and to better illustrate how policing practices differ across the three cities. By conducting this analysis, we can better understand racial disparities in policing and evaluate whether similar demographic groups are treated differently across major U.S. cities.\nResearch Question: How do racial disparities in traffic spots vary across San Diego (CA), Chicago (IL), and San Antonio (TX) for Black, Hispanic, and White Drivers?\nFirst, we must understand the proportion of drivers stopped in each city.\nCounting Total Vehicular Stops by Race for Each City\nChicago: Black drivers are the most frequently stopped in Chicago. Hispanic drivers are the second most stopped. White drivers, excluding NA values, are the 3rd most frequently stopped.\n\n\nshow code\nSELECT subject_race, COUNT(*) AS count \nFROM  il_chicago_2023_01_26\nWHERE type = 'vehicular' AND subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race \nORDER BY count DESC; \n\n\n\n3 records\n\n\nsubject_race\ncount\n\n\n\n\nblack\n868099\n\n\nhispanic\n358907\n\n\nwhite\n209901\n\n\n\n\n\nSan Diego: Hispanic drivers make up the 2nd largest proportion of stops in San Diego, with White drivers being the most frequently stopped. Black drivers are the 3rd most frequently stopped.\n\n\nshow code\nSELECT subject_race, COUNT(*) AS count \nFROM ca_san_diego_2020_04_01  \nWHERE type = 'vehicular' AND subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race \nORDER BY count DESC; \n\n\n\n3 records\n\n\nsubject_race\ncount\n\n\n\n\nwhite\n162226\n\n\nhispanic\n117083\n\n\nblack\n42705\n\n\n\n\n\n\nSan Antonio: Hispanic drivers make up the most frequent number of stops in San Antonio, followed by White drivers. Notably, there are fewer number of NA values recorded for San Antonio. Black drivers are the 3rd most frequently stopped in San Antonio.\n\n\nshow code\nSELECT subject_race, COUNT(*) AS count \nFROM  tx_san_antonio_2023_01_26 \nWHERE type = 'vehicular' AND subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race \nORDER BY count DESC; \n\n\n\n3 records\n\n\nsubject_race\ncount\n\n\n\n\nhispanic\n568800\n\n\nwhite\n382165\n\n\nblack\n105989\n\n\n\n\n\nInterpretation: Across the three cities, Chicago has a higher number of stops for Black drivers, San Diego has a higher number of stops for White drivers, and San Antonio has a higher number of stops for Hispanic drivers.\nNext, I will examine search rates, meaning how often drivers of each racial group are searched after being stopped to asses potential disparities in policing practices once someone is stopped.\nSearch Rates for Drivers by City\nChicago: Search proportions for Black drivers is ~0.98%, while for Hispanic drivers its ~0.81%, and ~0.27% for White drivers.\n\n\nshow code\nSELECT subject_race, \nSUM(search_conducted) as Num_Searches, \nCOUNT(*) as Total_Num_Stops \nFROM il_chicago_2023_01_26\nWHERE subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race\nORDER BY Num_Searches DESC;\n\n\n\n3 records\n\n\nsubject_race\nNum_Searches\nTotal_Num_Stops\n\n\n\n\nblack\n8533\n869647\n\n\nhispanic\n2919\n359121\n\n\nwhite\n586\n210274\n\n\n\n\n\nSan Diego: Out of 117083 stops made for Hispanic drivers in San Diego, 6501 of them resulted in a vehicular search, approximately 5.5%. The Hispanic search proportion (5.5%) is almost twice as high as that for White drivers (4510/162226 = ~2.7%) but almost half of that for Black drivers (3873/42705 = 9.06%).\n\n\nshow code\nSELECT subject_race, \nSUM(search_conducted) as Num_Searches, \nCOUNT(*) as Total_Num_Stops \nFROM ca_san_diego_2020_04_01 \nWHERE subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race\nORDER BY Num_Searches DESC;\n\n\n\n3 records\n\n\nsubject_race\nNum_Searches\nTotal_Num_Stops\n\n\n\n\nhispanic\n6501\n117083\n\n\nwhite\n4510\n162226\n\n\nblack\n3873\n42705\n\n\n\n\n\nSan Antonio: Hispanic proportion of searches is ~0.86% in San Antonio, while the Black proportion of searches is ~1.45% and for White drivers it is ~0.92%.\n\n\nshow code\nSELECT subject_race, \nSUM(search_conducted) as Num_Searches, \nCOUNT(*) as Total_Num_Stops \nFROM tx_san_antonio_2023_01_26\nWHERE subject_race IN ('white', 'black', 'hispanic')\nGROUP BY subject_race\nORDER BY Num_Searches DESC;\n\n\n\n3 records\n\n\nsubject_race\nNum_Searches\nTotal_Num_Stops\n\n\n\n\nhispanic\n5487\n633919\n\n\nwhite\n4548\n490230\n\n\nblack\n1913\n131762\n\n\n\n\n\n\nInterpretation: Across the 3 cities, the proportion of drivers who are searched after being stopped is higher for Black and Hispanic drivers than White drivers. It is especially interesting as in San Diego, where White drivers are the most frequently stopped but are the least searched after having been stopped, while Black drivers are the least frequently stopped yet the most proportionality searched if they are stopped. Overall, In the three cities, Black drivers tend to have the highest proportion of searches even if they are not the most frequently stopped (such as in San Diego and San Antonio). Hispanic drivers, in the three cities examined here, tend to be searched at a proportion rate higher than White drivers but lower rate than Black drivers.\nHow do Stop outcomes differ by race?\nTo examine the outcome of these stops, I want to analyze outcomes with two measures: proportions of stops that resulted in a citation and proportion of stops that resulted in an arrest.\nChicago: Citation rates are similar across races but arrest rates are substantially higher for Hispanic and White drivers. This may indicate that while citations are issued at similar rates, the escalation to arrest heavily varies.\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM il_chicago_2023_01_26 \nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \nORDER BY total_stops DESC;\n\n\n\n3 records\n\n\nsubject_race\ntotal_stops\ntotal_citations\ntotal_arrests\n\n\n\n\nblack\n869647\n9740\n91993\n\n\nhispanic\n359121\n4900\n75228\n\n\nwhite\n210274\n2530\n41556\n\n\n\n\n\nOf the total number of black drivers stopped in Chicago, ~1.12% received a citation, and ~10.58% were arrested. For Hispanic drivers ~1.36% received a citation, and ~20.9% were arrested. For White drivers ~1.20% received a citation, and ~19.7% were arrested.\n\n\nSan Diego: White and Hispanic drivers seem to receive citations at similar rates while Black drivers have a lower citation rate but a noticeably higher arrest rate. This suggests a different pattern of escalation than Chicago, as Black drivers seem to be less likely to get a citation but more likely to be arrested.\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM ca_san_diego_2020_04_01\nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \nORDER BY total_stops DESC;\n\n\n\n3 records\n\n\nsubject_race\ntotal_stops\ntotal_citations\ntotal_arrests\n\n\n\n\nwhite\n162226\n96631\n1771\n\n\nhispanic\n117083\n67787\n1714\n\n\nblack\n42705\n20728\n857\n\n\n\n\n\nOf the total number of black drivers stopped in San Diego, ~48.54% received a citation, and ~2.01% were arrested. For Hispanic drivers ~57.9% received a citation, and ~1.46% were arrested. For White drivers ~59.5% received a citation, and ~1.09% were arrested.\nSan Antonio: Arrest rates are low across all groups, but Black drivers are arrested at the highest proportion. Importantly, San Antonio’s data set likely records every stop as a citation thus the citation rate comparisons are not possible for this city (total_stops = total_citations as can be seen below.) Only arrest rates can be computed for this city, not citation rates.\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM tx_san_antonio_2023_01_26\nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \nORDER BY total_stops DESC;\n\n\n\n3 records\n\n\nsubject_race\ntotal_stops\ntotal_citations\ntotal_arrests\n\n\n\n\nhispanic\n633919\n633919\n1534\n\n\nwhite\n490230\n490230\n1342\n\n\nblack\n131762\n131762\n443\n\n\n\n\n\nThe arrest rate for White drivers is ~0.27%, for Hispanic drivers its ~0.24%, and ~0.34% for Black drivers.\nOverall Interpretation: Across the three cities, racial disparities in outcomes vary heavily. Chicago shows relatively similar citation rates across the three racial groups but higher arrest rates for Hispanic and White drivers. San Diego seems to have balanced citation rates among Hispanic and White drivers but lower citation rates for Black drivers, yet Black drivers also have the highest arrest rate. In San Antonio there are relatively low arrest rates but of the three racial groups, Black drivers have the highest proportion of arrests.\nOverall, there is no clear pattern that applies in how stops lead to a specific outcome. Instead, each city shows a set of disparities, suggesting that the outcome of a driver being stopped depends on both where the stop occurs and the race of the driver.\nData Visualizations: Outcomes by City and Race\nChicago\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM il_chicago_2023_01_26\nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \n\n\n\n\nshow code\nlibrary(tidyverse) \nchi_outcomes &lt;- chi_outcomes |&gt; \n  mutate(\n    citation_rate = total_citations / total_stops, \n    arrest_rate = total_arrests / total_stops, \n    city = \"Chicago\"\n  )\n\nchi_outcomes |&gt; select(total_stops, citation_rate, arrest_rate, city)\n\n\n  total_stops citation_rate arrest_rate    city\n1      869647    0.01119995   0.1057820 Chicago\n2      359121    0.01364443   0.2094781 Chicago\n3      210274    0.01203192   0.1976279 Chicago\n\n\nSan Diego\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM ca_san_diego_2020_04_01\nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \n\n\n\n\nshow code\nlibrary(tidyverse) \nsdiego_outcomes &lt;- sdiego_outcomes |&gt; \n  mutate(\n    citation_rate = total_citations / total_stops,\n    arrest_rate = total_arrests / total_stops, \n    city = \"San Diego\"\n  )\n\nsdiego_outcomes |&gt; select(total_stops, citation_rate, arrest_rate, city)\n\n\n  total_stops citation_rate arrest_rate      city\n1       42705     0.4853764  0.02006791 San Diego\n2      117083     0.5789653  0.01463919 San Diego\n3      162226     0.5956567  0.01091687 San Diego\n\n\nSan Antonio\n\n\nshow code\nSELECT subject_race, \nCOUNT(*) as total_stops, \nSUM(citation_issued) as total_citations, \nSUM(arrest_made) as total_arrests \nFROM tx_san_antonio_2023_01_26\nWHERE subject_race IN ('white', 'black', 'hispanic') \nGROUP BY subject_race \n\n\n\n\nshow code\nlibrary(tidyverse) \nsant_outcomes &lt;- sant_outcomes |&gt; \n  mutate(\n    arrest_rate = total_arrests / total_stops,\n    citation_rate = NA,\n    city = \"San Antonio\"\n  )\n\nsant_outcomes |&gt;\n  select(subject_race, arrest_rate, citation_rate) \n\n\n  subject_race arrest_rate citation_rate\n1        black 0.003362123            NA\n2     hispanic 0.002419868            NA\n3        white 0.002737491            NA\n\n\n\n\nshow code\nlibrary(tidyverse)\n\ncities &lt;- bind_rows(chi_outcomes, sdiego_outcomes, sant_outcomes)\n\nformat_piv &lt;- cities |&gt;\n  pivot_longer(\n    cols = c(citation_rate, arrest_rate),\n    names_to = \"outcome\",\n    values_to = \"rate\"\n  )\n\n\nCitation Rates Plot: The following visualization shows citation rates by race across the three cities. San Diego issues citations at notably higher rates for all groups, Chicago maintains very low citation rates overall, and San Antonio does not report citation data for this data set.\n\n\nshow code\ncitations_only &lt;- cities |&gt;\n  select(city, subject_race, citation_rate)\n\nggplot(citations_only, aes(x = subject_race, y = citation_rate, fill = subject_race)) +\n  geom_col() +\n  facet_wrap(~ city) +\n  labs(\n    title = \"Citation Rates by Race Across Cities\",\n    x = \"Driver Race\",\n    y = \"Citation Rate\"\n  ) +\n  theme_minimal() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nArrest Rates Plot: Arrest rates vary more sharply across cities. Chicago shows much higher arrest rates than San Diego and San Antonio, while both of the latter cities maintain very low arrest rates across all racial groups.\n\n\nshow code\narrests_only &lt;- cities |&gt;\n  select(city, subject_race, arrest_rate)\n\nggplot(arrests_only, aes(x = subject_race, y = arrest_rate, fill = subject_race)) +\n  geom_col() +\n  facet_wrap(~ city) +\n  labs(\n    title = \"Arrest Rates by Race Across Cities\",\n    x = \"Driver Race\",\n    y = \"Arrest Rate\"\n  ) +\n  theme_minimal() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nDisparities Plot: This plot highlights the size of the gap between citation and arrest rates for each racial group in each city, showing where those differences are largest.\n\n\nshow code\nggplot(format_piv, aes(x = outcome, y = rate, color = subject_race)) +\n  geom_point(size = 6) +\n  facet_wrap(~ city) +\n  labs(\n    title = \"Disparities in Citation & Arrest Rates\",\n    x = \"Outcome\",\n    y = \"Rate\",\n    color = \"Race\"\n  ) +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\nConclusion: Overall, this analysis helped highlight meaningful differences in policing patterns across the three cities. Even though Black and Hispanic drivers were not always the most frequently stopped, they often faced higher citation or arrest rates than white drivers. The visualizations illustrated these patterns by separating citation and arrest outcomes and showing how these rates vary by race within and across cities. It is important to note that the analysis was limited because the San Antonio data set did not include citation information, which restricts direct comparisons. Overall, the results suggest that enforcement practices are not applied evenly and that racial groups experience different outcomes even under similar stop conditions.\n\n\nshow code\ndbDisconnect(con_traffic, shutdown = TRUE)"
  },
  {
    "objectID": "NetflixData.html",
    "href": "NetflixData.html",
    "title": "Netflix Data",
    "section": "",
    "text": "Sources:\nTidyTuesday Data"
  },
  {
    "objectID": "NetflixData.html#netflix-engagement-report",
    "href": "NetflixData.html#netflix-engagement-report",
    "title": "Netflix Data",
    "section": " Netflix Engagement Report ",
    "text": "Netflix Engagement Report \n\n\nshow code\nlibrary(tidyverse)\n\n\n\n\nshow code\nmovies &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-29/movies.csv')\nshows &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-07-29/shows.csv')\n\n\n\n\nshow code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\n\nshow code\nshows |&gt; \n  filter(release_date &gt;= as.Date(\"2024-01-01\") & release_date &lt;= as.Date(\"2024-12-31\")) |&gt; \n  arrange(desc(hours_viewed)) |&gt; \n  slice(1:10) |&gt; \n  \n  ggplot(aes(x = release_date, y = hours_viewed)) + \n    geom_point(size = 2) + \n    labs(\n      title = \"Top 10 Netflix Shows Released in 2024: Hours Viewed vs Release Date\",\n      x = \"Release Date\",\n      y = \"Hours Viewed\"\n    )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi, there! I’m Evelyn, a current junior at Pomona College studying Economics with minors in Data Science and French. Outside of academics, I enjoy playing volleyball and going on runs!"
  },
  {
    "objectID": "IncomeInequality.html",
    "href": "IncomeInequality.html",
    "title": "Income Inequality",
    "section": "",
    "text": "Sources:\n TidyTuesday Data \n Ourworld Data \n\n\n\nshow code\nlibrary(tidyverse)\n\n\n\n\nshow code\nincome_inequality_processed &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-05/income_inequality_processed.csv')\nincome_inequality_raw &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-05/income_inequality_raw.csv')\n\n\n\n\nshow code\nggplot(income_inequality_processed, aes(x = gini_mi_eq)) +\n  geom_histogram(binwidth = 0.05, fill = \"blue\", color = \"white\", na.rm = TRUE) +\n  labs(\n    title = \"Distribution of Pre-Tax Income Inequality Across Countries\",\n    x = \"Gini Coefficient (Pre-Tax, Equivalized Income)\",\n    y = \"Number of Countries\"\n  )"
  },
  {
    "objectID": "cardata.html",
    "href": "cardata.html",
    "title": "Car Classes and Fuel Efficeny",
    "section": "",
    "text": "Citations\nArslaan, M. (2024). Explore car performance & fuel efficiency data [Dataset]. Kaggle. Retrieved from https://www.kaggle.com/datasets/arslaan5/explore-car-performance-fuel-efficiency-data\n Kaggle Data Source \nMotivation\nAs a college student that will likely be purchasing a car in the next few years, I want to make an informed decisions about fuel efficiency and long-term value. Given rising gas prices and environmental concerns, I am curious how different car classes (compact cars, SUV’s, etc) compare in terms of combined fuel efficency. These differences can help me chose a vehicle that balances performance, cost, and sustainability.\nWhat I Plan To Do:Using the dataset, Car Specifications and Performance Data from Kaggle, I will examine whether smaller cars are more fuel efficient than larger ones. I will begin by visualizing the combined (highway and city) miles per gallon (MPG) across two main car types (small and large) to see the general trends in efficiency. Next, I will calculate the difference in mean MPG between the car types to understand how much more or less efficient one group is compared to the pther. Finally, I will perform a permutation test to evaluate whether the observed difference is statistically significant or if it could have occurred by chance.\nResearch Question: Do small cars have a higher combined (highway and city) MPG than large cars?\nNull Hypothesis (H0): Car size has no effect on combined MPG.\nAlternative Hypothesis (HA): Small cars and large cars have different combined MPG.\n\n\nshow code\nlibrary(tidyverse)\nlibrary(ggplot2) \n\ncar_data &lt;- read.csv(\"car_data.csv\")  \n\n\n\n\nshow code\nlibrary(tidyverse) \n\nsmall_class &lt;- c(\"compact car\", \"midsize car\", \"minicompact car\", \"subcompact car\", \"midsize station wagon\", \"small station wagon\", \"two seater\") \n\nlarge_class &lt;- c(\"large car\", \"minivan\", \"small pickup truck\", \"standard pickup truck\", \"small sport utility vehicle\", \"standard sport utility vehicle\")  \n\ncars_clean &lt;- car_data |&gt; \n  filter(fuel_type == \"gas\", !is.na(combination_mpg), !is.na(class)) |&gt; \n  mutate(car_type = if_else(class %in% small_class, \"small\", \"large\"))\n\nggplot(cars_clean, aes(x = car_type, y = combination_mpg, fill = car_type)) + geom_boxplot() + \n  labs(title = \"Combined MPG by Car Class Type\", \n       x = \"Car Type\", \n       y = \"Combined MPG\") + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nBoxplot: This boxplot compares the Combined MPG (an average of city and highway fuel efficiency) between small and large cars. The car_type variable groups car classes into “small” and “large”, and the plot shows the distributions, median, and outliers of MPG for each car type group. This helps to visualize which car type tends to be more fuel-efficient.\nNext step: I will calculate the p-value to asses the probability that the observed difference of 1.42 occurred by chance, and use a permutation test to determine whether this difference between small and large cars is statistically significant.\n\n\nshow code\nlibrary(tidyverse) \nset.seed(47) \n\nperm_null &lt;- function(data) {\n  shuffled &lt;- data |&gt; mutate(car_type = sample(car_type))\n  diff &lt;- mean(shuffled$combination_mpg[shuffled$car_type == \"small\"]) -\n          mean(shuffled$combination_mpg[shuffled$car_type == \"large\"])\n  return(diff)\n}\n\nperm_null_results &lt;- map_dbl(1:1000, ~ perm_null(cars_clean))  \n\nobs_diff &lt;- mean(cars_clean$combination_mpg[cars_clean$car_type == \"small\"]) - \n  mean(cars_clean$combination_mpg[cars_clean$car_type == \"large\"]) \n\n\np_value &lt;- mean(abs(perm_null_results) &gt;= abs(obs_diff)) \n\nggplot(data.frame(diff = perm_null_results), aes(x = diff)) +\n  geom_histogram(bins = 30, fill = \"lightblue\" , color = \"black\") + geom_vline(xintercept = obs_diff, color = \"red\", linewidth = 1) +\n  labs(title = \"Permutation Test: Null Distribution of Mean Differences\", \n       subtitle = \"Based on 1,000 shuffles of Car Type labels, P-value = 0.003\", \n       x = \"Difference in Mean MPG (Small - Large)\",\n       y = \"Frequency\") + theme_minimal()\n\n\n\n\n\n\n\n\n\nHistogram: This histogram demonstrates the distribution of mean MPG (miles-per-gallon) differences between small and large cars under 1,000 random shuffles of car types. The observed difference of 1.42 MPG is marked with the red vertical line. This visualizes the differences we’d expected by chance alone if car size had no effect on MPG (null hypothesis).\nInterpretation: The observed difference in mean MPG between small and large cars was 1.42, while the permutation test produced a p-value of 0.003. While the null hypothesis stated that car size has no effect on MPG and any observed difference is due to random chance, the low p-value (below 0.01) provides very strong evidence against the null hypothesis, suggesting that car size does indeed have a statistically significant effect on fuel efficiency.\nWrap-up: For my analysis, I compared the fuel efficiency (combined MPG) of small and large cars using data from the Car Specifications and Performance Data dataset. After categorizing the data (deciding which car classes were “small” and which were “large”), I visualized the difference in MPG between the two groups with a boxplot. I then conducted a permutation test with 1,000 random shuffles to assess whether the observed difference in mean MPG could be due to chance. The results provided strong evidence against the null hypothesis, suggesting that the difference in fuel efficiency between small and large cars is unlikely to be due to random variation. This information can help consumers like myself make more informed decisions when choosing a car that offers better long-term fuel efficiency."
  },
  {
    "objectID": "nytimes.html",
    "href": "nytimes.html",
    "title": "NYT Article Data",
    "section": "",
    "text": "Citation:\nBoydstun, A. E. (n.d.). NYTimes dataset University of California, Davis. Retrieved from http://www.amberboydstun.com/\nhttp://www.amberboydstun.com/\" &gt; R Data Source \nAnalysis 1: How Often Are Female and Male Terms Used in NYT Articles?\n\n\nshow code\nlibrary(tidyverse)\nlibrary(RTextTools) \n\ndata(NYTimes)\n\nNYTimes &lt;- NYTimes |&gt; \n  mutate( \n    Title = as.character(Title),\n    Subject = as.character(Subject)\n  )\n\n\nTibble below counts the number of times female terms or male terms are found in the data set’s headlines:\n\n\nshow code\nnyt_obj &lt;- NYTimes |&gt; \n  select(Date, Title, Subject) |&gt; \n  filter(!is.na(Title)) |&gt;\n  mutate(\n    title_subj = str_to_lower(str_c(Title, Subject, sep = \" \"))\n  )\n\n\nfem_names &lt;- \"\\\\b(woman | women | girl | girls | female | females)\\\\b\" \nmale_names &lt;- \"\\\\b(men | man | males | males | boy | boys)\\\\b\"\n\nnyt_obj &lt;- nyt_obj |&gt; \n  mutate(\n    fem_mentioned = str_detect(title_subj, fem_names) ,\n    male_mentioned = str_detect(title_subj, male_names)\n  )\n\ncounts_mentions &lt;- nyt_obj |&gt; \n  summarise(\n    fem_count = sum(fem_mentioned), \n    male_count = sum(male_mentioned)\n  ) |&gt; \n  pivot_longer(cols = everything(), \n               names_to = \"gender\",\n               values_to = \"count\"\n               ) \n\ncounts_mentions \n\n\n# A tibble: 2 × 2\n  gender     count\n  &lt;chr&gt;      &lt;int&gt;\n1 fem_count     25\n2 male_count    28\n\n\n\n\nshow code\ncounts_mentions |&gt; \n  ggplot(aes(x= gender, y = count, fill = gender)) + \n  geom_col(show.legend = FALSE) + \n  labs(\n    title = \"Mentions of Gendered Terms in NYT Article Titles 1996-2006\", \n    x = \"Gender Mentioned\" ,\n    y = \"Number of Mentions\"\n  ) + theme_light()\n\n\n\n\n\n\n\n\n\nData Process: This graph demonstrates how many times female or male gendered terms appeared in the data set (which contains 3104 articles total). The graph is a product of wrangling the data set such that key words “woman, women, girl, girls, female, females” are regarded as female terms and male terms include “men, man, males, males, boy, boys.” These gendered keywords are looked for in both the Titles and Subjects of each article. After identifying how many times female or male terms are detected in the data set articles, they are displayed in the column graph above.\nTo better understand what these counts mean relative to the data set, the next step is to take the proportion of articles that mention female, male, and both. The data wrangling for this is in the code below and it’s results displayed in the graph below.\n\n\nshow code\nprop_mentions &lt;- nyt_obj |&gt;\n  summarise(\n    total_articles = n(),\n    fem_articles = sum(fem_mentioned, na.rm = TRUE),\n    male_articles = sum(male_mentioned, na.rm = TRUE),\n    both_articles = sum(fem_mentioned & male_mentioned, na.rm = TRUE)\n  ) |&gt;\n\npivot_longer(\n    cols = c(fem_articles, male_articles, both_articles),\n    names_to = \"category\",\n    values_to = \"count\"\n  ) |&gt;\n  mutate(proportion = count / total_articles) \n\nggplot(prop_mentions, aes(x= category, y = proportion, fill = category)) + geom_col(show.legend = FALSE) + \n         labs(\n  title = \"Porportion of NYT Articles Mentioning Gendered Terms (1996-2006)\",\n  x = \"Gender Mentions\",\n  y = \"Proportion of All Articles\"\n) + theme_light()\n\n\n\n\n\n\n\n\n\nThe graph above shows the proportion of articles from the New York Times that used gendered terms between 1996-2006. To find this proportion, I used the previously wrangled data to calculate each genders’ mentions proportional to the total number of articles in the data set.\nGraph Analysis 1: Between the span of the data set (1996-2006), headlines in *The New York Times* show a subtle but consistent gender imbalance. The proportion of articles mentioning men (0.0090) is slightly higher than the proportion of articles mentioning women (0.0080), while the proportion of headlines referencing both (0.0032) is relatively rare. While the differences are small, this suggests that articles that referenced females and/or males were rare, such that, once added, only about 2% of articles mentioned gender. The remaining 98% made no explicit mention of gender, or at least no mention of the keywords. This suggests that most coverage was focused on topics where gender wasn’t mentioned in the headline and/or subject. A possible reason for this maybe the political and global focus of the era, dominated by events such as 9/11 attacks and the wars in the middle east. The era’s coverage thus likely centered around conflict, policy, and international affairs rather than gendered narratives such as those including social trends, lifestyle, etc.\nAnalysis 2: Do headlines mentioning gender tend to be longer or shorter than those that don’t?\n\n\nshow code\nNYTimes_lengths &lt;- nyt_obj |&gt; \n  mutate(title_length = str_count( Title, \"\\\\S+\"),\n  gender_mentioned = fem_mentioned | male_mentioned)\n\ngender_lengths &lt;- NYTimes_lengths |&gt; \n  group_by(gender_mentioned) |&gt; \n  summarise(avg_length = mean(title_length))\n\n\n\n\nshow code\nNYTimes_lengths |&gt;\n  \nggplot(aes(x = gender_mentioned, y = title_length, fill = gender_mentioned)) + \n  geom_boxplot() + \n  labs(title = \"Title Lengths: With Gender Mentions vs. Without\",\n       x = \"Gender Mention\", \n       y = \"Title Length (words count) \" \n       ) + theme_light() + theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nGraph Analysis 2: This graph shows that headlines mentioning gender (male, female, and both) tended to be slightly longer, averaging about 8.9 words per title compared to 8.2 words per title for those without gender mentions. The median length is also higher for gendered headlines, showing a small but consistent pattern. The range and presence of outliers (including some headlines that are more than 20 words) indicate that a few gendered headlines require substantially more context or description. This suggest that when gender was mentioned, The New York Times felt it was necessary to provide more context or descriptive verbiage. This may have been done to reflect additional nuance in gender-related topics, for example, a headline like ’Politics: The Democrat; Clinton Campaigns Puts an Emphasis on Women’ (1996) uses ten words, requiring additional language to emphasize both its gendered focus and its political context. Overall, this suggests that gendered headlines, even if fewer in number within the data set, tend to include more context or detail than non-gendered ones.\nFinal Analysis: What are the top 5 words that follow after “woman”?\n\n\nshow code\nafter_women &lt;- nyt_obj |&gt; \n  mutate(\n    word_after_woman = str_extract(\n      title_subj,\n      \"(?&lt;=\\\\bwomen\\\\s)\\\\w+\"\n    )\n  )\n\nafter_women |&gt; \n  filter(!is.na(word_after_woman)) |&gt; \n  select(word_after_woman, title_subj) |&gt; \n  count(word_after_woman, sort = TRUE) |&gt; \n  arrange(desc(n)) |&gt; \n  head(5)\n\n\n  word_after_woman n\n1               in 3\n2              and 1\n3            bound 1\n4        dismissed 1\n5             gain 1\n\n\nSo, what comes after the “women in”..?\n\n\nshow code\nafter_women_in &lt;- nyt_obj |&gt; \n  mutate(\n  after_in = str_extract(\n  title_subj, \n  \"(?&lt;=\\\\bwomen\\\\sin\\\\s)\\\\w+\"\n  )  \n  )\n\nafter_women_in |&gt; \n  filter(!is.na(after_in)) |&gt; \n  select(after_in, title_subj) |&gt; \n  count(after_in, sort = TRUE) |&gt; \n  arrange(desc(n))\n\n\n  after_in n\n1   africa 1\n2   france 1\n3 military 1\n\n\nAnalysis 3: Building on analyses 1 and 2, which showed that gendered terms are rare but lengthen headlines by a bit, the words that follow the word “women” reveal additonal context. Admittedly, one could run the code for every single term that was categorized as a female term, but for this analysis, I chose to just examine the words that came after “women.”\nThe most common word after “women” is “in”, often referring to places or institutions, such as “Africa”, “France”, or “military.” While this does not capture all female terms, it suggests that in this small sample of headlines, when women are mentioned, it is frequently in relation to locations. This aligns with analyses 1 and 2, where topics were noted to be mostly political and few were gendered, likely reflecting the era’s political focus."
  },
  {
    "objectID": "ethicalConsiderations.html",
    "href": "ethicalConsiderations.html",
    "title": "Target Pregnancy Predicitve Model",
    "section": "",
    "text": "Citations\nDuhigg, C. (2012, February 16). How companies learn your secrets. The New York Times Magazine. https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?unlocked_article_code=1.6U4.nLSt.-yehBjKHEmPW&smid=url-share\nTarget Corporation. (2025, June 30). Privacy Policy https://www.target.com/c/target-privacy-policy/-/N-4sr7p\nContext: In 2012, the New York Times Magazine published Charles Duhhig’s piece titled, “How Companies Learn Your Secrets,” in which he described his conversations with Andrew Pole, a Target statistician since 2002. Pole explained that the company had assigned him the task of gathering customer information to answer the question, “If we wanted to figure out if a customer is pregnant, even if she didn’t want us to know, can we?” Duhigg explored how Target’s predictive analytics department used data to anticipate customer behavior and increase profit. Through his reporting, Duhigg revealed how Target used customer data to build a prediction model capable of identifying when a woman was pregnant, estimating her due date, and delivering tailored ads, coupons, and product recommendations. Pregnant women were specifically targeted because companies found that people’s shopping habits changed most during major life events, and pregnancy was a prime opportunity for Target to shape pregnant women’s habits early on, during, and after her pregnancy.\nThe data science component in this case is the use of predictive modeling to infer personal information from shopping data. The ethical issue lies in the intent and transparency of this data collection. Female shoppers were unaware that Target was attempting to determine pregnancy status, and as noted in the article, Target deliberately kept the project private as they feared public backlash. The company’s secrecy itself reveals its awareness of the ethical implications.\nWhat is the permission structure for using the data? Was it followed?\nTarget’s current privacy policy explains that it may collect and use customer data from online orders, in-store purchases, customer service interactions, loyalty programs, the Target app, and Target.com accounts. As the policy states, this information is collected because “you [customers] provide it to us.” The policy allows for automated data collection and third-party tracking to create a “personalized experience no matter how you interact with us [Target].” Even back in 2012, Target’s privacy terms technically permitted such practices. Legally, the company followed its publicly stated permission structure. Yet, the intent to predict pregnancy without explicitly informing customers reveals a serious ethical dilemma. Interestingly, although Target operated within their legal ability, using data to build a model that tracks and predicts intimate personal details without disclosure might be considered crossing into exploitation. Further, Target’s goal with this analysis and model –to increase their company profit– makes this even more ethically questionable despite its technical legality.\nWhat was the consent structure for recruiting participants? Were the participants aware of the ways their data would be used for research? Was informed consent possible? Can you provide informed consent for applications that are yet foreseen?\nTarget customers, both in 2012 and today, consent to data collection implicitly through the terms of service and opt-in features, rather than through direct, informed consent. Simply shopping in-store or online counts as agreement. When questioned by Duhigg, Target declined to comment in detail, stating only that it was “in compliance with all federal and state laws, including those related to protected health information.” While customers generally understand that companies may collect their data for marketing, they did not know that Target was using purchasing patterns (for example, monitoring when they purchased vitamins and lotion) to predict pregnancy. Given that Target uses a “Guest ID” system, this information would then be inputted, such that the shopper was marked with their pregnancy prediction on some Target data set. As previously stated, female shoppers did not knowingly consent to having such sensitive, personal, and health-related information inferred about them. Informed consent would have required explicit awareness of this use, which Target avoided for fear of making customers uncomfortable or attracting negative press. Informed consent, given target’s privacy policy, was technically there but true informed consent would have required explicit awareness of this data use, which the company avoided for worry of making customers uncomfortable or attracting negative press. Additionally, it does not seem possible for customers to consent to data applications that are yet foreseen, as they cannot meaningfully or fully understand what large corporations intend to use, or sell, their data for.\nWhat was the data collection process? Were the observations collected ethically? Are there missing observations? \nTarget’s data collection linked each customer’s online and in-store activity through a unique “Guest ID” that recorded every purchase and connected it to demographic data. As Pole described, Target wanted to “know everything [they] can.” Data were gathered through both direct interactions and automated collection, but in the case of the pregnancy model, Target inferred deeply personal information from ordinary transactions (daily purchases and company interaction) without disclosure. Today, Target’s privacy policy explicitly allows the collection of “inferences drawn [from data you’ve given them access to],” formalizing what was once implicit. Although the process is now legal and stated, ethical issues remain as customers still do not meaningfully understand or approve of how their data may be used. Thus, while the collection process was technically legal back in 2012, and is stated in their privacy policy, it continues to blur the line between data analysis and intrusion on customer’s privacy. Missing observations may include customers who are not a part of loyalty programs or account holders. From a data science standpoint, the missing data may weaken the predictive model, as non-target account holders or frequent shoppers are not captured. However, from an ethics standpoint, less data protects some customer’s autonomy and privacy.\n\nThe “Data Values and Principles manifesto” states, “As data teams, we aim too…use data to improve life for our users, customers, organizations, and communities.”\nThe Data Values and Principles Manifesto states, “As data teams, we aim to… use data to improve life for our users, customers, organizations, and communities.” Target’s approach fails to meet this principle. While one could argue that predictive modeling might help expecting mothers by offering relevant products, the stronger argument is that Target’s actions primarily served its own commercial interests. The race for predicting their customers’ pregnancy status was not out of genuine care, but to win against competitors for those customers’ money. The secrecy surrounding the model, as reported by Duhigg, shows that Target never intended transparency. It is ironic that the company wished to keep its model private while exploiting private information about its customers. The data and data collection practices in this instance benefit the corporation, not the individuals whose data were used. Though Target claims to enhance customer experience, its predictive analytics program manipulates consumer behavior without explicit consent. This imbalance of benefit violates the manifesto’s standard of equitable and responsible data use, as while Target gains insight and control, customers lose privacy.\nSummary\nThis ethical dilemma in data science matters because this case exposes how a large corporation is willing to violate its customers’ privacy for profit. As the article notes, Target is not unique as most major corporations have data analytics teams and predictive models designed to detect, and then influence consumer behavior to maximize revenue. In these situations, corporations and their executives benefit, while ordinary shoppers are harmed, as their data is used and inferred without meaningful consent. The ethical violations here served profit and power, as Target sought to predict pregnancy before anyone else could to capture customers at a vulnerable stage and then hid the process, which makes the practice even more ethically indefensible."
  },
  {
    "objectID": "DSpresentation.html#overview",
    "href": "DSpresentation.html#overview",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "Overview",
    "text": "Overview\n\nTarget used customer purchase data to predict when female shoppers were pregnant in order to influence shopping habits early.\nMain issue: Target customers were unaware that their data was being used to infer intimate, health-related information.\nThe case raises questions about a corporation’s ethical obligations even when their actions are technically legal."
  },
  {
    "objectID": "DSpresentation.html#background-targets-model",
    "href": "DSpresentation.html#background-targets-model",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "Background: Target’s Model",
    "text": "Background: Target’s Model\n\nTarget statistician Andrew Pole was tasked with determining whether they could identify pregnancy from purchase history.\nTheir model inferred pregnancy and due date using shopping patterns like that of vitamins and lotions.\nThe company kept this project private, aware it would spark backlash."
  },
  {
    "objectID": "DSpresentation.html#the-incident",
    "href": "DSpresentation.html#the-incident",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "The incident",
    "text": "The incident\n\nBased on Charles Duhhig’s New York Times Magazine piece, “How Companies Learn Your Secrets.”\nA father confronted Target after his teenage daughter received targeted coupons for baby products.\nThe model had correctly inferred her pregnancy before her family knew.\nThis revealed the existence of Target’s pregnancy prediction algorithm and sparked scrutiny from the public."
  },
  {
    "objectID": "DSpresentation.html#ethical-analysis",
    "href": "DSpresentation.html#ethical-analysis",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "Ethical Analysis",
    "text": "Ethical Analysis\nAs of Target’s privacy policy, the company is technically allowed broad data collection, including a wide range of information from any guest who uses in-store, online, or in‑app services.\nWhile these practices are covered in Target’s privacy policy, it’s unlikely customers knew their data could be used to infer such personal information. At the time of the incident, shoppers probably did not explicitly agree to these terms."
  },
  {
    "objectID": "DSpresentation.html#ethical-standards-it-fails",
    "href": "DSpresentation.html#ethical-standards-it-fails",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "Ethical Standards It Fails",
    "text": "Ethical Standards It Fails\nContrasted against the Data Values and Principles Manifesto Target’s predictive model violated key principles…\n\nServed corporate profit, not customer benefit\n\nThe data was not used to improve the life of users and communities. Instead, it primarily served the company’s interest.\n\nLacked transparency and true consent\n\nCustomers were unable to make informed decisions of future use of their data as Target did not disclose exactly how the data was used or that the model existed.\nInsights were used to manipulate consumer behavior."
  },
  {
    "objectID": "DSpresentation.html#summary",
    "href": "DSpresentation.html#summary",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "Summary",
    "text": "Summary\nThis case shows how predictive analytics can cross ethical boundaries even when legal. Shoppers lost privacy and autonomy, while Target gained commercially. It raises important questions about a company’s ethical responsibilities in using consumer data."
  },
  {
    "objectID": "DSpresentation.html#references",
    "href": "DSpresentation.html#references",
    "title": "Target’s Predictive Pregnancy Model",
    "section": "References",
    "text": "References\nDuhigg, C. (2012, February 16). How companies learn your secrets. The New York Times Magazine. https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html?unlocked_article_code=1.6U4.nLSt.-yehBjKHEmPW&smid=url-share\nTarget Corporation. (2025, June 30). Privacy Policy https://www.target.com/c/target-privacy-policy/-/N-4sr7p"
  }
]